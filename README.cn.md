# LocalAIStack

[English README](README.md)

**LocalAIStack** 是一个开放、模块化的软件栈，用于构建和运营 **本地 AI 工作站**。

它提供统一的控制层，用于在本地硬件上安装、管理、升级并运行 AI 开发环境、推理运行时、模型和应用 —— 无需依赖云服务或厂商专有平台。

LocalAIStack 旨在 **硬件感知**、**可复现**、**可扩展**，作为本地 AI 计算的长期基础。

---

## 为什么选择 LocalAIStack

本地运行 AI 工作负载不再是小众需求。
然而，本地 AI 软件生态仍然高度碎片化：

* 推理引擎、框架与应用彼此独立演进
* CUDA、驱动、Python 与系统依赖高度耦合
* 不同硬件配置的安装路径不一致
* 环境漂移导致难以复现与维护
* 许多工具默认面向云端部署模型

LocalAIStack 通过将 **本地 AI 工作站本身视为基础设施** 来解决这些问题。

---

## 设计目标

LocalAIStack 围绕以下原则构建：

* **本地优先**
  不强制依赖云端，必要时可完全离线运行。

* **硬件感知**
  自动基于 CPU、GPU、内存和互联能力适配可用软件能力。

* **模块化与可组合**
  所有组件可选且可独立管理。

* **默认可复现**
  安装与运行行为可确定且可版本化。

* **开放且厂商中立**
  不锁定特定硬件厂商、模型或框架。

---

## 文档

更详细的技术设计已整理到 `docs/` 目录，以保持 README 简洁且一致：

* [架构设计（英文版）](./docs/architecture.md)
* [模块系统与清单规范（英文版）](./docs/modules.md)
* [硬件能力与策略映射（英文版）](./docs/policies.md)
* [运行时执行模型（英文版）](./docs/runtime.md)

---

## LocalAIStack 提供什么

LocalAIStack 是面向本地 AI 工作站的分层系统，整体提供：

* 可确定的安装、升级与回滚路径
* 与硬件能力绑定的运行时选择与策略控制
* 可独立启用或移除的模块化组件
* 管理运行时、服务与应用的统一入口

---

## 典型使用场景

* 本地 LLM 推理与实验
* RAG 与智能体开发
* AI 教育与教学实验室
* 研究复现性
* 企业私有 AI 环境
* 硬件评估与基准测试

---

## 开源

LocalAIStack 是一个开源项目。

* 许可证：Apache 2.0（或 MIT，待定）
* 欢迎贡献
* 设计上保持厂商中立

---

## 项目状态

LocalAIStack 正在积极开发中。

当前初期重点为：

* 稳定的 Tier 2（≈30B）本地推理流程
* 可确定的安装路径
* 清晰的硬件到能力映射

随着项目演进，将发布路线图与里程碑。

---

## 快速开始

文档、安装指南和清单位于 `docs/` 目录。

---

## 理念

LocalAIStack 将 **本地 AI 计算视为基础设施**，而不是一组工具。

它希望让本地 AI 系统：

* 可预测
* 易维护
* 易理解
* 可长期使用
