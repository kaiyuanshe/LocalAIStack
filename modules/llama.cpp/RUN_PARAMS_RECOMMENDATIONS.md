# llama.cpp 运行参数建议

本文给出在 Linux 环境下使用 `llama.cpp`（`llama-server` / `llama-cli`）时的实用参数建议，目标是先稳定可用，再逐步提高吞吐和延迟表现。

## 1. 推荐优先级（先调这些）

1. `-m` / `--model`：模型路径（必须）
2. `-c` / `--ctx-size`：上下文长度，直接影响内存占用
3. `-ngl` / `--gpu-layers`：GPU 卸载层数，直接影响速度
4. `-t` / `--threads`：CPU 线程数，影响预填充和解码
5. `--batch-size` / `-b`：批大小，影响吞吐与显存占用
6. 采样参数（`--temp` / `--top-p` / `--top-k` / `--repeat-penalty`）

## 2. 快速起步模板

> 以下命令中的参数名在不同版本可能有轻微差异，请以 `llama-server --help` 和 `llama-cli --help` 为准。

### 2.1 本地 API 服务（通用稳定版）

```bash
llama-server \
  -m /path/to/model.gguf \
  -c 4096 \
  -ngl 999 \
  -t 8 \
  -b 512 \
  --host 127.0.0.1 \
  --port 8080
```

适用场景：单机本地调用、优先稳定。

### 2.2 高质量生成（问答/写作）

```bash
llama-cli \
  -m /path/to/model.gguf \
  -c 8192 \
  -ngl 999 \
  -t 8 \
  --temp 0.7 \
  --top-p 0.9 \
  --top-k 40 \
  --repeat-penalty 1.1
```

### 2.3 低随机性（代码/结构化输出）

```bash
llama-cli \
  -m /path/to/model.gguf \
  -c 4096 \
  -ngl 999 \
  -t 8 \
  --temp 0.2 \
  --top-p 0.9 \
  --top-k 20 \
  --repeat-penalty 1.05
```

## 3. 核心参数建议

### 3.1 上下文长度 `-c`

- 建议默认：`4096`
- 需要长上下文时：`8192` 或更高
- 注意：上下文越大，内存/显存占用越高，首 token 延迟通常也会上升

### 3.2 GPU 卸载层数 `-ngl`

- 有可用显卡时优先：`-ngl 999`（尽量全卸载）
- 显存不足时逐步下调：`999 -> 80 -> 60 -> 40 -> 20`
- 观察指标：是否 OOM、吞吐（tok/s）是否明显改善

### 3.3 线程数 `-t`

- 建议起点：物理核数或略低于物理核数
- 常见起点：`4 / 8 / 16`
- 过大线程数可能导致上下文切换开销增加，吞吐反降

### 3.4 批大小 `-b` / `--batch-size`

- 建议起点：`256` 或 `512`
- 吞吐优先可尝试更大值
- 显存紧张或延迟敏感场景可下调

### 3.5 采样参数（生成质量）

- 平衡方案（推荐默认）：
  - `--temp 0.7`
  - `--top-p 0.9`
  - `--top-k 40`
  - `--repeat-penalty 1.1`
- 更确定（代码/抽取）：
  - `--temp 0.1 ~ 0.3`
  - `--top-k 20 ~ 40`
- 更发散（创意）：
  - `--temp 0.8 ~ 1.0`
  - `--top-p 0.9 ~ 0.95`

## 4. 按硬件档位建议

### 4.1 纯 CPU

- 量化优先选更小模型或更高量化（如 Q4）
- `-t` 取物理核附近
- `-c` 从 `2048/4096` 起步，避免过大导致内存压力

### 4.2 消费级单卡 GPU

- 先用 `-ngl 999`，若 OOM 再降
- `-b` 从 `512` 起步，逐步增加到稳定上限
- 长上下文任务再提升 `-c`，避免一开始把显存吃满

### 4.3 显存紧张

- 降低 `-c`
- 降低 `-b`
- 降低 `-ngl`
- 选择更高量化版本

## 5. 调参顺序（推荐）

1. 固定模型与量化
2. 先设 `-c`（按业务最长输入）
3. 调 `-ngl` 到“不 OOM 且速度最好”
4. 调 `-b` 找吞吐与稳定平衡点
5. 调 `-t` 找 CPU 最优点
6. 最后再调采样参数保证输出质量

## 6. 常见问题与处理

- OOM（内存/显存不足）：
  - 先降 `-c`，再降 `-b`，再降 `-ngl`
- 输出重复或啰嗦：
  - 提高 `--repeat-penalty`（如 `1.1 -> 1.15`）
  - 降低 `--temp`
- 输出太死板：
  - 适度提高 `--temp` 或 `--top-p`
- 吞吐低：
  - 检查是否成功 GPU 卸载（`-ngl`）
  - 调整 `-b` 与 `-t`，避免线程过高

## 7. 最小可维护运行基线

建议在生产或长期运行中至少固定以下参数：

- 模型路径：`-m`
- 上下文：`-c`
- GPU 卸载层：`-ngl`
- 线程数：`-t`
- 批大小：`-b`
- 采样组：`--temp --top-p --top-k --repeat-penalty`

同时保留一份已验证命令模板，避免不同调用方随意漂移参数。
