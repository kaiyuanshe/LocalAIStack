{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AOG Speech-to-Text Example\n",
    "\n",
    "This notebook demonstrates how to use AOG Speech-to-Text API to convert speech to text.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Environment Setup](#1-Environment Setup)\n",
    "2. [Helper Functions](#2-Helper Functions)\n",
    "3. [Basic Speech Recognition](#3-Basic Speech Recognition)\n",
    "4. [Multi-language Recognition](#4-Multi-language Recognition)\n",
    "5. [Timeline Processing](#5-Timeline Processing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import base64\n",
    "import json\n",
    "from typing import Optional, Dict, List\n",
    "from pathlib import Path\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "# AOG service configuration\n",
    "AOG_BASE_URL = \"http://localhost:16688\"\n",
    "AOG_API_SPEC_VERSION = \"v0.2\"\n",
    "DEFAULT_MODEL = \"NamoLi/whisper-large-v3-ov\"\n",
    "\n",
    "print(\"âœ… Configuration complete\")\n",
    "print(f\"ğŸ“ AOG service address: {AOG_BASE_URL}\")\n",
    "print(f\"ğŸ¤– Default model: {DEFAULT_MODEL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_to_base64(audio_path: str) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    å°†éŸ³é¢‘æ–‡ä»¶è½¬æ¢ä¸º base64 ç¼–ç \n",
    "    \n",
    "    Args:\n",
    "        audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„\n",
    "    \n",
    "    Returns:\n",
    "        base64 ç¼–ç å­—ç¬¦ä¸²\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(audio_path, \"rb\") as f:\n",
    "            audio_data = f.read()\n",
    "            return base64.b64encode(audio_data).decode()\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ éŸ³é¢‘ç¼–ç å¤±è´¥: {e}\")\n",
    "        return None\n",
    "\n",
    "def call_aog_stt(\n",
    "    audio_base64: str,\n",
    "    model: str = DEFAULT_MODEL,\n",
    "    language: Optional[str] = None\n",
    ") -> Optional[Dict]:\n",
    "    \"\"\"\n",
    "    Call AOG Speech-to-Text API\n",
    "    \n",
    "    Args:\n",
    "        audio_base64: base64 ç¼–ç éŸ³é¢‘æ•°æ®\n",
    "        model: Model name\n",
    "        language: è¯­è¨€ä»£ç  (zh/en/ç­‰)\n",
    "    \n",
    "    Returns:\n",
    "        API response data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        url = f\"{AOG_BASE_URL}/aog/{AOG_API_SPEC_VERSION}/services/speech-to-text\"\n",
    "        \n",
    "        payload = {\n",
    "            \"model\": model,\n",
    "            \"audio\": audio_base64\n",
    "        }\n",
    "        \n",
    "        if language:\n",
    "            payload[\"language\"] = language\n",
    "        \n",
    "        print(f\"ğŸ“¤ Sending request...\")\n",
    "        if language:\n",
    "            print(f\"ğŸŒ è¯­è¨€: {language}\")\n",
    "        \n",
    "        response = requests.post(url, json=payload, timeout=120)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        print(\"âœ… Recognition successful\")\n",
    "        return response.json()\n",
    "        \n",
    "    except requests.exceptions.ConnectionError:\n",
    "        print(\"âŒ æ— æ³•è¿æ¥åˆ° AOG æœåŠ¡\")\n",
    "        return None\n",
    "    except requests.exceptions.Timeout:\n",
    "        print(\"âŒ Request timeout,éŸ³é¢‘æ–‡ä»¶å¯èƒ½è¿‡å¤§\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ é”™è¯¯: {e}\")\n",
    "        return None\n",
    "\n",
    "def print_segments(response: Optional[Dict]):\n",
    "    \"\"\"\n",
    "    æ ¼å¼åŒ–æ‰“å°Recognition result\n",
    "    \n",
    "    Args:\n",
    "        response: API response data\n",
    "    \"\"\"\n",
    "    if not response:\n",
    "        return\n",
    "    \n",
    "    segments = response.get(\"segments\", [])\n",
    "    \n",
    "    if not segments:\n",
    "        print(\"âš ï¸  æ²¡æœ‰Recognition result\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ğŸ“ Recognition result:\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for segment in segments:\n",
    "        seg_id = segment.get(\"id\", 0)\n",
    "        start = segment.get(\"start\", \"\")\n",
    "        end = segment.get(\"end\", \"\")\n",
    "        text = segment.get(\"text\", \"\")\n",
    "        \n",
    "        print(f\"\\n[{seg_id}] {start} --> {end}\")\n",
    "        print(f\"    {text}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    \n",
    "    # æ‰“å°å®Œæ•´æ–‡æœ¬\n",
    "    full_text = \" \".join([seg.get(\"text\", \"\") for seg in segments])\n",
    "    print(\"\\nğŸ“„ å®Œæ•´æ–‡æœ¬:\")\n",
    "    print(full_text)\n",
    "    print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "print(\"âœ… Helper Functionså®šä¹‰å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Basic Speech Recognition\n",
    "\n",
    "Note:éœ€è¦å‡†å¤‡ä¸€ä¸ªæµ‹è¯•éŸ³é¢‘æ–‡ä»¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åŸºæœ¬ç¤ºä¾‹\n",
    "# è¯·å°† 'your_audio.wav' æ›¿æ¢ä¸ºå®é™…éŸ³é¢‘æ–‡ä»¶è·¯å¾„\n",
    "audio_path = \"your_audio.wav\"\n",
    "\n",
    "if Path(audio_path).exists():\n",
    "    # æ˜¾ç¤ºéŸ³é¢‘\n",
    "    print(\"ğŸ”Š åŸå§‹éŸ³é¢‘:\")\n",
    "    display(Audio(audio_path))\n",
    "    \n",
    "    # è½¬æ¢ä¸º base64\n",
    "    audio_base64 = audio_to_base64(audio_path)\n",
    "    \n",
    "    if audio_base64:\n",
    "        # è°ƒç”¨ API\n",
    "        response = call_aog_stt(audio_base64)\n",
    "        \n",
    "        # æ‰“å°ç»“æœ\n",
    "        print_segments(response)\n",
    "else:\n",
    "    print(f\"âš ï¸  éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_path}\")\n",
    "    print(\"è¯·å‡†å¤‡ä¸€ä¸ªæµ‹è¯•éŸ³é¢‘æ–‡ä»¶å¹¶æ›´æ–°è·¯å¾„\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Multi-language Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¸­æ–‡è¯†åˆ«\n",
    "if Path(audio_path).exists():\n",
    "    audio_base64 = audio_to_base64(audio_path)\n",
    "    \n",
    "    if audio_base64:\n",
    "        print(\"ğŸ‡¨ğŸ‡³ ä¸­æ–‡è¯†åˆ«\")\n",
    "        response = call_aog_stt(audio_base64, language=\"zh\")\n",
    "        print_segments(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è‹±æ–‡è¯†åˆ«\n",
    "if Path(audio_path).exists():\n",
    "    audio_base64 = audio_to_base64(audio_path)\n",
    "    \n",
    "    if audio_base64:\n",
    "        print(\"ğŸ‡ºğŸ‡¸ è‹±æ–‡è¯†åˆ«\")\n",
    "        response = call_aog_stt(audio_base64, language=\"en\")\n",
    "        print_segments(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Timeline Processing\n",
    "\n",
    "æå–å’Œå¤„ç†æ—¶é—´è½´ä¿¡æ¯,å¯ç”¨äºç”Ÿæˆå­—å¹•ç­‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_srt(segments: List[Dict], output_file: str = \"subtitles.srt\"):\n",
    "    \"\"\"\n",
    "    ç”Ÿæˆ SRT å­—å¹•æ–‡ä»¶\n",
    "    \n",
    "    Args:\n",
    "        segments: Recognition resultåˆ†æ®µæ•°ç»„\n",
    "        output_file: è¾“å‡ºæ–‡ä»¶å\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            for segment in segments:\n",
    "                seg_id = segment.get(\"id\", 0) + 1\n",
    "                start = segment.get(\"start\", \"00:00:00.000\").replace(\".\", \",\")\n",
    "                end = segment.get(\"end\", \"00:00:00.000\").replace(\".\", \",\")\n",
    "                text = segment.get(\"text\", \"\")\n",
    "                \n",
    "                f.write(f\"{seg_id}\\n\")\n",
    "                f.write(f\"{start} --> {end}\\n\")\n",
    "                f.write(f\"{text}\\n\\n\")\n",
    "        \n",
    "        print(f\"âœ… å­—å¹•æ–‡ä»¶å·²ç”Ÿæˆ: {output_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ç”Ÿæˆå­—å¹•å¤±è´¥: {e}\")\n",
    "\n",
    "# ç”Ÿæˆå­—å¹•ç¤ºä¾‹\n",
    "if Path(audio_path).exists():\n",
    "    audio_base64 = audio_to_base64(audio_path)\n",
    "    \n",
    "    if audio_base64:\n",
    "        response = call_aog_stt(audio_base64)\n",
    "        \n",
    "        if response and \"segments\" in response:\n",
    "            generate_srt(response[\"segments\"])\n",
    "            \n",
    "            # æ˜¾ç¤ºå­—å¹•å†…å®¹\n",
    "            with open(\"subtitles.srt\", \"r\", encoding=\"utf-8\") as f:\n",
    "                print(\"\\nğŸ“„ ç”Ÿæˆå­—å¹•æ–‡ä»¶å†…å®¹:\")\n",
    "                print(\"=\"*60)\n",
    "                print(f.read())\n",
    "                print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ‰ Summary\n",
    "\n",
    "Through this notebook, you have learned:\n",
    "\n",
    "1. âœ… è°ƒç”¨ Speech-to-Text API\n",
    "2. âœ… å¤„ç†éŸ³é¢‘æ–‡ä»¶(base64 ç¼–ç )\n",
    "3. âœ… Multi-language Recognition\n",
    "4. âœ… è§£ææ—¶é—´è½´ä¿¡æ¯\n",
    "5. âœ… ç”Ÿæˆ SRT å­—å¹•æ–‡ä»¶\n",
    "\n",
    "### ä½¿ç”¨æŠ€å·§\n",
    "\n",
    "- ğŸ¤ ä½¿ç”¨æ¸…æ™°éŸ³é¢‘æé«˜è¯†åˆ«å‡†ç¡®ç‡\n",
    "- ğŸŒ æŒ‡å®šæ­£ç¡®è¯­è¨€Args\n",
    "- â±ï¸ åˆ©ç”¨æ—¶é—´è½´ä¿¡æ¯ç”Ÿæˆå­—å¹•\n",
    "- ğŸ“ æ”¯æŒå¤šç§éŸ³é¢‘æ ¼å¼\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- å°è¯•ä¸åŒè¯­è¨€éŸ³é¢‘\n",
    "- æµ‹è¯•é•¿éŸ³é¢‘æ–‡ä»¶\n",
    "- Check out [å®æ—¶è¯­éŸ³è¯†åˆ«ç¤ºä¾‹](../speech-to-text-ws/)\n",
    "- Check out [æ–‡æœ¬è½¬è¯­éŸ³ç¤ºä¾‹](../text-to-speech/)\n",
    "- Read [AOG API æ–‡æ¡£](../../docs/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}