{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AOG Embed Service Example\n",
    "\n",
    "This notebook demonstrates how to use AOG Embed API to generate text embedding vectors.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Environment Setup](#1-Environment Setup)\n",
    "2. [Helper Functions](#2-Helper Functions)\n",
    "3. [Basic Embedding Generation](#3-Basic Embedding Generation)\n",
    "4. [Similarity Calculation](#4-Similarity Calculation)\n",
    "5. [Semantic Search](#5-Semantic Search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import numpy as np\n",
    "from typing import List, Optional, Dict\n",
    "\n",
    "# AOG service configuration\n",
    "AOG_BASE_URL = \"http://localhost:16688\"\n",
    "AOG_API_SPEC_VERSION = \"v0.2\"\n",
    "DEFAULT_MODEL = \"text-embedding-v3\"\n",
    "\n",
    "print(\"âœ… Configuration complete\")\n",
    "print(f\"ğŸ“ AOG service address: {AOG_BASE_URL}\")\n",
    "print(f\"ğŸ¤– Default model: {DEFAULT_MODEL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_aog_embed(\n",
    "    texts: List[str],\n",
    "    model: str = DEFAULT_MODEL\n",
    ") -> Optional[Dict]:\n",
    "    \"\"\"\n",
    "    Call AOG Embed API\n",
    "    \n",
    "    Args:\n",
    "        texts: List of texts\n",
    "        model: Model name\n",
    "    \n",
    "    Returns:\n",
    "        API response data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        url = f\"{AOG_BASE_URL}/aog/{AOG_API_SPEC_VERSION}/services/embed\"\n",
    "        \n",
    "        payload = {\n",
    "            \"model\": model,\n",
    "            \"input\": texts\n",
    "        }\n",
    "        \n",
    "        print(f\"ğŸ“¤ Sending request...\")\n",
    "        print(f\"ğŸ“ æ–‡æœ¬æ•°é‡: {len(texts)}\")\n",
    "        \n",
    "        response = requests.post(url, json=payload, timeout=60)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        print(\"âœ… åµŒå…¥Generation successful\")\n",
    "        return response.json()\n",
    "        \n",
    "    except requests.exceptions.ConnectionError:\n",
    "        print(\"âŒ æ— æ³•è¿æ¥åˆ° AOG æœåŠ¡\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ é”™è¯¯: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_embeddings(texts: List[str], model: str = DEFAULT_MODEL) -> Optional[np.ndarray]:\n",
    "    \"\"\"\n",
    "    è·å–æ–‡æœ¬åµŒå…¥å‘é‡\n",
    "    \n",
    "    Args:\n",
    "        texts: List of texts\n",
    "        model: Model name\n",
    "    \n",
    "    Returns:\n",
    "        åµŒå…¥å‘é‡æ•°ç»„ (numpy array)\n",
    "    \"\"\"\n",
    "    response = call_aog_embed(texts, model)\n",
    "    \n",
    "    if not response or \"data\" not in response:\n",
    "        return None\n",
    "    \n",
    "    # æå–åµŒå…¥å‘é‡\n",
    "    embeddings = []\n",
    "    for item in response[\"data\"]:\n",
    "        embeddings.append(item[\"embedding\"])\n",
    "    \n",
    "    return np.array(embeddings)\n",
    "\n",
    "def cosine_similarity(vec1: np.ndarray, vec2: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    è®¡ç®—ä¸¤ä¸ªå‘é‡ä½™å¼¦ç›¸ä¼¼åº¦\n",
    "    \n",
    "    Args:\n",
    "        vec1: å‘é‡1\n",
    "        vec2: å‘é‡2\n",
    "    \n",
    "    Returns:\n",
    "        ç›¸ä¼¼åº¦åˆ†æ•° (0-1)\n",
    "    \"\"\"\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm1 = np.linalg.norm(vec1)\n",
    "    norm2 = np.linalg.norm(vec2)\n",
    "    return dot_product / (norm1 * norm2)\n",
    "\n",
    "def find_most_similar(query_embedding: np.ndarray, doc_embeddings: np.ndarray, docs: List[str], top_k: int = 3):\n",
    "    \"\"\"\n",
    "    æ‰¾åˆ°æœ€ç›¸ä¼¼æ–‡æ¡£\n",
    "    \n",
    "    Args:\n",
    "        query_embedding: æŸ¥è¯¢åµŒå…¥å‘é‡\n",
    "        doc_embeddings: æ–‡æ¡£åµŒå…¥å‘é‡æ•°ç»„\n",
    "        docs: æ–‡æ¡£List of texts\n",
    "        top_k: Returnså‰ k ä¸ªæœ€ç›¸ä¼¼æ–‡æ¡£\n",
    "    \n",
    "    Returns:\n",
    "        æœ€ç›¸ä¼¼æ–‡æ¡£åŠå…¶ç›¸ä¼¼åº¦\n",
    "    \"\"\"\n",
    "    similarities = []\n",
    "    \n",
    "    for i, doc_emb in enumerate(doc_embeddings):\n",
    "        sim = cosine_similarity(query_embedding, doc_emb)\n",
    "        similarities.append((i, sim, docs[i]))\n",
    "    \n",
    "    # æŒ‰ç›¸ä¼¼åº¦æ’åº\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return similarities[:top_k]\n",
    "\n",
    "print(\"âœ… Helper Functionså®šä¹‰å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Basic Embedding Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åŸºæœ¬ç¤ºä¾‹\n",
    "texts = [\n",
    "    \"äººå·¥æ™ºèƒ½æ­£åœ¨æ”¹å˜ä¸–ç•Œ\",\n",
    "    \"æœºå™¨å­¦ä¹ æ˜¯AIä¸€ä¸ªImportantåˆ†æ”¯\",\n",
    "    \"æ·±åº¦å­¦ä¹ ä½¿ç”¨ç¥ç»ç½‘ç»œ\"\n",
    "]\n",
    "\n",
    "response = call_aog_embed(texts)\n",
    "\n",
    "if response:\n",
    "    print(\"\\nğŸ“Š å“åº”ä¿¡æ¯:\")\n",
    "    print(f\"æ¨¡å‹: {response.get('model')}\")\n",
    "    print(f\"è¯·æ±‚ID: {response.get('id')}\")\n",
    "    print(f\"åµŒå…¥æ•°é‡: {len(response.get('data', []))}\")\n",
    "    \n",
    "    # æ˜¾ç¤ºç¬¬ä¸€ä¸ªåµŒå…¥å‘é‡ç»´åº¦\n",
    "    if response.get('data'):\n",
    "        first_embedding = response['data'][0]['embedding']\n",
    "        print(f\"å‘é‡ç»´åº¦: {len(first_embedding)}\")\n",
    "        print(f\"å‘é‡å‰10ä¸ªå€¼: {first_embedding[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Similarity Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è®¡ç®—æ–‡æœ¬ç›¸ä¼¼åº¦\n",
    "text_pairs = [\n",
    "    (\"æˆ‘å–œæ¬¢åƒè‹¹æœ\", \"æˆ‘å–œæ¬¢åƒæ°´æœ\"),\n",
    "    (\"æˆ‘å–œæ¬¢åƒè‹¹æœ\", \"ä»Šå¤©å¤©æ°”å¾ˆå¥½\"),\n",
    "    (\"æœºå™¨å­¦ä¹ å¾ˆæœ‰è¶£\", \"æ·±åº¦å­¦ä¹ å¾ˆå¼ºå¤§\")\n",
    "]\n",
    "\n",
    "print(\"\\nğŸ“Š æ–‡æœ¬Similarity Calculation:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for text1, text2 in text_pairs:\n",
    "    # è·å–åµŒå…¥\n",
    "    embeddings = get_embeddings([text1, text2])\n",
    "    \n",
    "    if embeddings is not None and len(embeddings) == 2:\n",
    "        # è®¡ç®—ç›¸ä¼¼åº¦\n",
    "        similarity = cosine_similarity(embeddings[0], embeddings[1])\n",
    "        \n",
    "        print(f\"\\næ–‡æœ¬1: {text1}\")\n",
    "        print(f\"æ–‡æœ¬2: {text2}\")\n",
    "        print(f\"ç›¸ä¼¼åº¦: {similarity:.4f}\")\n",
    "        print(\"-\" * 60)\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Semantic Search\n",
    "\n",
    "æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨åµŒå…¥å‘é‡forSemantic Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ–‡æ¡£åº“\n",
    "documents = [\n",
    "    \"Pythonæ˜¯ä¸€ç§æµè¡Œç¼–ç¨‹è¯­è¨€\",\n",
    "    \"æœºå™¨å­¦ä¹ å¯ä»¥ç”¨äºæ•°æ®åˆ†æ\",\n",
    "    \"æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ å­é›†\",\n",
    "    \"è‡ªç„¶è¯­è¨€å¤„ç†å¤„ç†æ–‡æœ¬æ•°æ®\",\n",
    "    \"è®¡ç®—æœºè§†è§‰å¤„ç†å›¾åƒæ•°æ®\",\n",
    "    \"å¼ºåŒ–å­¦ä¹ é€šè¿‡è¯•é”™æ¥å­¦ä¹ \",\n",
    "    \"ç¥ç»ç½‘ç»œæ¨¡æ‹Ÿäººè„‘ç»“æ„\",\n",
    "    \"æ•°æ®ç§‘å­¦ç»“åˆç»Ÿè®¡å’Œç¼–ç¨‹\"\n",
    "]\n",
    "\n",
    "# ç”Ÿæˆæ–‡æ¡£åµŒå…¥\n",
    "print(\"ğŸ“š ç”Ÿæˆæ–‡æ¡£åµŒå…¥...\")\n",
    "doc_embeddings = get_embeddings(documents)\n",
    "\n",
    "if doc_embeddings is not None:\n",
    "    print(f\"âœ… å·²ç”Ÿæˆ {len(doc_embeddings)} ä¸ªæ–‡æ¡£åµŒå…¥å‘é‡\\n\")\n",
    "    \n",
    "    # æŸ¥è¯¢ç¤ºä¾‹\n",
    "    queries = [\n",
    "        \"ä»€ä¹ˆæ˜¯æ·±åº¦å­¦ä¹ ?\",\n",
    "        \"å¦‚ä½•å¤„ç†æ–‡æœ¬?\",\n",
    "        \"ç¼–ç¨‹è¯­è¨€æœ‰å“ªäº›?\"\n",
    "    ]\n",
    "    \n",
    "    for query in queries:\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(f\"ğŸ” æŸ¥è¯¢: {query}\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # ç”ŸæˆæŸ¥è¯¢åµŒå…¥\n",
    "        query_embedding = get_embeddings([query])\n",
    "        \n",
    "        if query_embedding is not None:\n",
    "            # æ‰¾åˆ°æœ€ç›¸ä¼¼æ–‡æ¡£\n",
    "            results = find_most_similar(query_embedding[0], doc_embeddings, documents, top_k=3)\n",
    "            \n",
    "            print(\"\\nğŸ“„ æœ€ç›¸å…³æ–‡æ¡£:\")\n",
    "            for rank, (idx, similarity, doc) in enumerate(results, 1):\n",
    "                print(f\"\\n{rank}. ç›¸ä¼¼åº¦: {similarity:.4f}\")\n",
    "                print(f\"   æ–‡æ¡£: {doc}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ‰ Summary\n",
    "\n",
    "Through this notebook, you have learned:\n",
    "\n",
    "1. âœ… è°ƒç”¨ Embed API ç”ŸæˆåµŒå…¥å‘é‡\n",
    "2. âœ… è®¡ç®—æ–‡æœ¬ç›¸ä¼¼åº¦\n",
    "3. âœ… å®ç°Semantic Search\n",
    "4. âœ… å¤„ç†æ‰¹é‡æ–‡æœ¬åµŒå…¥\n",
    "\n",
    "### åº”ç”¨åœºæ™¯\n",
    "\n",
    "- ğŸ” **Semantic Search**: æ ¹æ®è¯­ä¹‰è€Œéå…³é”®è¯åŒ¹é…æŸ¥æ‰¾ç›¸å…³å†…å®¹\n",
    "- ğŸ“Š **æ–‡æœ¬èšç±»**: å°†ç›¸ä¼¼æ–‡æœ¬åˆ†ç»„\n",
    "- ğŸ¯ **æ¨èç³»ç»Ÿ**: åŸºäºå†…å®¹ç›¸ä¼¼åº¦æ¨è\n",
    "- ğŸ“ **æ–‡æœ¬åˆ†ç±»**: ä½¿ç”¨åµŒå…¥å‘é‡ä½œä¸ºç‰¹å¾\n",
    "- ğŸ”— **å»é‡**: è¯†åˆ«é‡å¤æˆ–ç›¸ä¼¼æ–‡æœ¬\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- å°è¯•ä¸åŒæ–‡æœ¬å’ŒæŸ¥è¯¢\n",
    "- é›†æˆå‘é‡æ•°æ®åº“(Milvusã€Pinecone)\n",
    "- æ„å»ºå®Œæ•´Semantic Searchç³»ç»Ÿ\n",
    "- Check out [Chat æœåŠ¡ç¤ºä¾‹](../text-generation/)\n",
    "- Read [AOG API æ–‡æ¡£](../../docs/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}