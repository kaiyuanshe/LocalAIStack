{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AOG Text Generation Example\n",
    "\n",
    "This notebook demonstrates how to use the AOG Chat API for text generation and conversation.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Environment Setup](#1-Environment-Setup)\n",
    "2. [Helper Functions](#2-Helper-Functions)\n",
    "3. [Basic Chat Example](#3-Basic-Chat-Example)\n",
    "4. [Different Message Types](#4-Different-Message-Types)\n",
    "5. [Multi-turn Conversation](#5-Multi-turn-Conversation)\n",
    "6. [Parameter Configuration](#6-Parameter-Configuration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup\n",
    "\n",
    "First, import necessary libraries and configure AOG service connection parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import requests\n",
    "import json\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "# AOG service configuration\n",
    "AOG_BASE_URL = \"http://localhost:16688\"  # Modify this if service is at a different address\n",
    "AOG_API_SPEC_VERSION = \"v0.2\"\n",
    "DEFAULT_MODEL_CHAT = \"qwen2.5:0.5b\"  # Default chat model\n",
    "\n",
    "print(\"âœ… Configuration complete\")\n",
    "print(f\"ðŸ“ AOG service address: {AOG_BASE_URL}\")\n",
    "print(f\"ðŸ¤– Default model: {DEFAULT_MODEL_CHAT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Helper Functions\n",
    "\n",
    "Define helper functions to call the AOG Chat API with complete error handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_aog_chat(\n",
    "    messages: List[Dict[str, str]], \n",
    "    model: str = DEFAULT_MODEL_CHAT, \n",
    "    stream: bool = False\n",
    ") -> Optional[Dict]:\n",
    "    \"\"\"\n",
    "    Call AOG Chat API\n",
    "    \n",
    "    Args:\n",
    "        messages: List of messages, each containing role and content\n",
    "        model: Model name to use\n",
    "        stream: Whether to use streaming response\n",
    "    \n",
    "    Returns:\n",
    "        JSON data from API response, or None if failed\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Construct API endpoint URL\n",
    "        url = f\"{AOG_BASE_URL}/aog/{AOG_API_SPEC_VERSION}/services/chat\"\n",
    "        \n",
    "        # Construct request payload\n",
    "        payload = {\n",
    "            \"model\": model,\n",
    "            \"messages\": messages,\n",
    "            \"stream\": stream\n",
    "        }\n",
    "        \n",
    "        # Send POST request\n",
    "        response = requests.post(url, json=payload, timeout=30)\n",
    "        \n",
    "        # Check response status\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Return JSON response\n",
    "        return response.json()\n",
    "        \n",
    "    except requests.exceptions.ConnectionError:\n",
    "        print(\"âŒ Cannot connect to AOG service, please ensure service is running\")\n",
    "        print(f\"   Check service address: {AOG_BASE_URL}\")\n",
    "        return None\n",
    "        \n",
    "    except requests.exceptions.Timeout:\n",
    "        print(\"âŒ Request timeout, please check network connection or increase timeout\")\n",
    "        return None\n",
    "        \n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        print(f\"âŒ API call failed: {e}\")\n",
    "        print(f\"   Response content: {response.text}\")\n",
    "        return None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Unknown error: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def print_response(response: Optional[Dict]) -> None:\n",
    "    \"\"\"\n",
    "    Format and print API response\n",
    "    \n",
    "    Args:\n",
    "        response: API response data\n",
    "    \"\"\"\n",
    "    if response is None:\n",
    "        print(\"âš ï¸  No response received\")\n",
    "        return\n",
    "    \n",
    "    # Extract assistant's reply\n",
    "    if \"choices\" in response and len(response[\"choices\"]) > 0:\n",
    "        message = response[\"choices\"][0].get(\"message\", {})\n",
    "        content = message.get(\"content\", \"\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"ðŸ¤– Assistant reply:\")\n",
    "        print(\"=\"*60)\n",
    "        print(content)\n",
    "        print(\"=\"*60 + \"\\n\")\n",
    "    else:\n",
    "        print(\"âš ï¸  Abnormal response format\")\n",
    "        print(json.dumps(response, indent=2, ensure_ascii=False))\n",
    "\n",
    "print(\"âœ… Helper functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Basic Chat Example\n",
    "\n",
    "Simplest chat example: send a user message and get an AI reply."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a simple user message\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Hello! Please introduce yourself.\"}\n",
    "]\n",
    "\n",
    "print(\"ðŸ“¤ Sending message...\")\n",
    "response = call_aog_chat(messages)\n",
    "print_response(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Different Message Types\n",
    "\n",
    "Demonstrate how to use different message types: system, user, assistant.\n",
    "\n",
    "### 4.1 Using System Message to Set Role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use system message to define AI assistant's role\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a professional Python programming assistant, skilled at explaining code and providing programming advice.\"},\n",
    "    {\"role\": \"user\", \"content\": \"How do I read a JSON file in Python?\"}\n",
    "]\n",
    "\n",
    "print(\"ðŸ“¤ Sending message (with system role setting)...\")\n",
    "response = call_aog_chat(messages)\n",
    "print_response(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Different System Prompt Effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different system prompts\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a humorous assistant who likes to use metaphors and examples to explain problems.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is machine learning?\"}\n",
    "]\n",
    "\n",
    "print(\"ðŸ“¤ Sending message (humorous style)...\")\n",
    "response = call_aog_chat(messages)\n",
    "print_response(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Multi-turn Conversation\n",
    "\n",
    "Implement contextually coherent multi-turn conversation by maintaining conversation history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize conversation history\n",
    "conversation = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a friendly assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"I want to learn Python, where should I start?\"}\n",
    "]\n",
    "\n",
    "print(\"ðŸ—£ï¸  First round of conversation\")\n",
    "print(\"User: I want to learn Python, where should I start?\")\n",
    "response = call_aog_chat(conversation)\n",
    "print_response(response)\n",
    "\n",
    "# Add assistant's reply to conversation history\n",
    "if response and \"choices\" in response:\n",
    "    assistant_message = response[\"choices\"][0][\"message\"]\n",
    "    conversation.append(assistant_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue conversation - second round\n",
    "conversation.append({\n",
    "    \"role\": \"user\", \n",
    "    \"content\": \"Do I need to install any software?\"\n",
    "})\n",
    "\n",
    "print(\"ðŸ—£ï¸  Second round of conversation\")\n",
    "print(\"User: Do I need to install any software?\")\n",
    "response = call_aog_chat(conversation)\n",
    "print_response(response)\n",
    "\n",
    "# Continue adding to conversation history\n",
    "if response and \"choices\" in response:\n",
    "    assistant_message = response[\"choices\"][0][\"message\"]\n",
    "    conversation.append(assistant_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View complete conversation history\n",
    "print(\"\\nðŸ“œ Complete conversation history:\")\n",
    "print(\"=\"*60)\n",
    "for i, msg in enumerate(conversation, 1):\n",
    "    role = msg[\"role\"]\n",
    "    content = msg[\"content\"]\n",
    "    print(f\"\\n{i}. [{role.upper()}]\")\n",
    "    print(content[:200] + \"...\" if len(content) > 200 else content)\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Parameter Configuration\n",
    "\n",
    "Demonstrate how to configure different parameters.\n",
    "\n",
    "### 6.1 Using Different Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use specified model\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Explain what artificial intelligence is in one sentence.\"}\n",
    "]\n",
    "\n",
    "print(f\"ðŸ“¤ Using model: {DEFAULT_MODEL_CHAT}\")\n",
    "response = call_aog_chat(messages, model=DEFAULT_MODEL_CHAT)\n",
    "print_response(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Streaming vs Non-streaming Response\n",
    "\n",
    "Note: This example uses non-streaming response (`stream=False`), which waits for the complete result before returning.\n",
    "Streaming response (`stream=True`) returns results word by word, suitable for scenarios requiring real-time display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-streaming response (default)\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Write a short poem about spring.\"}\n",
    "]\n",
    "\n",
    "print(\"ðŸ“¤ Using non-streaming response (stream=False)\")\n",
    "response = call_aog_chat(messages, stream=False)\n",
    "print_response(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ‰ Summary\n",
    "\n",
    "Through this notebook, you have learned:\n",
    "\n",
    "1. âœ… Configure AOG service connection\n",
    "2. âœ… Call Chat API for basic conversation\n",
    "3. âœ… Use different message types (system, user, assistant)\n",
    "4. âœ… Implement multi-turn conversation with context\n",
    "5. âœ… Configure model parameters\n",
    "6. âœ… Handle API errors and exceptions\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Try different system prompts to explore AI's different roles\n",
    "- Implement more complex conversation logic\n",
    "- Check out [Text-to-Image Example](../text-to-image/text-to-image.ipynb)\n",
    "- Read [AOG API Documentation](../../docs/) for more features\n",
    "\n",
    "**Happy coding!** ðŸš€"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}